{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTbot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UHsydH6Gu7ft"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjiY7OQFvoip"
      },
      "source": [
        "## Fine Tuning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTqrTI2AqTbD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY7mmcj9pRcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d4e764-ad14-41ff-b529-46717e5f176b"
      },
      "source": [
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNAzuvKPgMuV",
        "scrolled": true
      },
      "source": [
        "# install huggingface libraries\n",
        "# !pip install pytorch-pretrained-bert pytorch-nlp pytorch_transformers\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp pytorch_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0wMey3UD0pN"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig, BertModel\n",
        "from pytorch_transformers import AdamW, BertForQuestionAnswering\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf2v9SoKgdAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdb782ef-4ee0-4a8e-9149-b8c8d69dabc8"
      },
      "source": [
        "# BERT imports\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxU6tT62gg-J",
        "outputId": "bb240747-1082-41ee-fccc-d1c2379e0003"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8doMAIhiM2f"
      },
      "source": [
        "# checking if data is stored correctly in Colab Notebooks/data\n",
        "!ls /drive/My\\ Drive/Colab\\ Notebooks/data/*.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIoPb8BviFD1"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/drive/My Drive/Colab Notebooks/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRjv5YLTiwiK"
      },
      "source": [
        "from utils_squad import (read_squad_examples, convert_examples_to_features,\n",
        "                         RawResult, write_predictions,\n",
        "                         RawResultExtended, write_predictions_extended)\n",
        "from utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad, plot_pr_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR8ZcIyllCop",
        "outputId": "e908a743-641e-4c7d-ddef-a99f9178ba56"
      },
      "source": [
        "# cuda is an NVIDIA toolkit that provides a dev environment for GPU-accelerated apps\n",
        "# checking if cuda is available to use GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QKVV05rmbyq"
      },
      "source": [
        "# getting a could not find answer error, this stems from not being able to find the answer\n",
        "# exactly how it is in the context because either added tokens or lowercase uppercase\n",
        "# WARNING: do not edit the answers when labelling\n",
        "input_file = '/drive/My Drive/Colab Notebooks/data/data_struct_ext-v1.1.json'\n",
        "# reading in the input .json file\n",
        "# the version_2_with_negative: if true, the SQuAD examples contain some that do not have an answer\n",
        "examples = read_squad_examples(input_file=input_file,\n",
        "                                is_training=True,\n",
        "                                version_2_with_negative=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BnYG0WK5hfF",
        "scrolled": false,
        "outputId": "90567af1-fa1b-46d0-feb3-b2a9d6a59096"
      },
      "source": [
        "examples[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[qas_id: a5570602-91e4-4fca-9d1a-e1d24877a615, question_text: what are some data structures used to store lists?, doc_tokens: [LISTS=====Let’s consider two different data structures for storing a list of things:an array and a linked list.], start_position: 4, end_position: 16,\n",
              " qas_id: 81476860-90cf-4481-bfa5-1d8d77d1ec47, question_text: what is the advantage of using an array to store a list?, doc_tokens: [An array is a pretty obvious way to store a list, with a big advantage: itenables very fast access of each item. However, it has two disadvantages.], end_position: 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "QM55tNxXl9xS",
        "scrolled": true,
        "outputId": "927fe7f4-8b6d-4e95-f2a4-51cc076c44ca"
      },
      "source": [
        "# creating a pandas df from the examples loaded above\n",
        "train_data = pd.DataFrame.from_records([vars(example) for example in examples])\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qas_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>doc_tokens</th>\n",
              "      <th>orig_answer_text</th>\n",
              "      <th>start_position</th>\n",
              "      <th>end_position</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a5570602-91e4-4fca-9d1a-e1d24877a615</td>\n",
              "      <td>what are some data structures used to store li...</td>\n",
              "      <td>[LISTS=====Let’s, consider, two, different, da...</td>\n",
              "      <td>data structures for storing a list of things:a...</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81476860-90cf-4481-bfa5-1d8d77d1ec47</td>\n",
              "      <td>what is the advantage of using an array to sto...</td>\n",
              "      <td>[An, array, is, a, pretty, obvious, way, to, s...</td>\n",
              "      <td>An array is a pretty obvious way to store a li...</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ec176d1d-1c33-46d3-a58f-9d19d372ad5a</td>\n",
              "      <td>what is the disadvantage of storing a list usi...</td>\n",
              "      <td>[First,, if, we, want, to, insert, an, item, a...</td>\n",
              "      <td>First, if we want to insert an item at the beg...</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c7e42265-ce26-4b63-b768-09eb950d31c8</td>\n",
              "      <td>how long does inserting an item in an array take?</td>\n",
              "      <td>[First,, if, we, want, to, insert, an, item, a...</td>\n",
              "      <td>This takes timeproportional to the length of t...</td>\n",
              "      <td>29</td>\n",
              "      <td>37</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>537f441e-315c-4a42-887b-453fc86ef005</td>\n",
              "      <td>what is the disadvantage of using an array to ...</td>\n",
              "      <td>[Second,, an, array, has, a, fixed, length, th...</td>\n",
              "      <td>an array has a fixed length that can’t be chan...</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 qas_id  ... is_impossible\n",
              "0  a5570602-91e4-4fca-9d1a-e1d24877a615  ...         False\n",
              "1  81476860-90cf-4481-bfa5-1d8d77d1ec47  ...         False\n",
              "2  ec176d1d-1c33-46d3-a58f-9d19d372ad5a  ...         False\n",
              "3  c7e42265-ce26-4b63-b768-09eb950d31c8  ...         False\n",
              "4  537f441e-315c-4a42-887b-453fc86ef005  ...         False\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "9G0MrPcUl9xT",
        "scrolled": false,
        "outputId": "b250c957-ecfb-439b-ac2b-100574a75b70"
      },
      "source": [
        "# taking a sample from the train_data above\n",
        "# display the first row -> head(1)\n",
        "sample = train_data.sample(frac=1).head(1)\n",
        "context = sample.doc_tokens.values\n",
        "train_data[train_data.doc_tokens.values==context]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qas_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>doc_tokens</th>\n",
              "      <th>orig_answer_text</th>\n",
              "      <th>start_position</th>\n",
              "      <th>end_position</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>49a74458-2dee-417b-bbc1-a939af566328</td>\n",
              "      <td>what is an adjacency list?</td>\n",
              "      <td>[Representing, a, Graph, Using, an, Adjacency,...</td>\n",
              "      <td>Adjacency list = a list (either an array or li...</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>adf087b3-492f-4a25-9ba8-6fd2d4a313a7</td>\n",
              "      <td>when is an adjacency list representation of a ...</td>\n",
              "      <td>[Representing, a, Graph, Using, an, Adjacency,...</td>\n",
              "      <td>This representation is good if a graph is spar...</td>\n",
              "      <td>50</td>\n",
              "      <td>66</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>aaff94db-24c8-4113-b678-dc57a32f1ab7</td>\n",
              "      <td>how are missing edges represented in adjacency...</td>\n",
              "      <td>[Representing, a, Graph, Using, an, Adjacency,...</td>\n",
              "      <td>No memory is allocated for non-existent edges,...</td>\n",
              "      <td>33</td>\n",
              "      <td>49</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   qas_id  ... is_impossible\n",
              "448  49a74458-2dee-417b-bbc1-a939af566328  ...         False\n",
              "449  adf087b3-492f-4a25-9ba8-6fd2d4a313a7  ...         False\n",
              "450  aaff94db-24c8-4113-b678-dc57a32f1ab7  ...         False\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE5lXGQbl9xT"
      },
      "source": [
        "import random\n",
        "# pick a random context and print out the questions and answers associated with it in a pretty format\n",
        "def print_squad_sample(train_data, line_length=14, separator_length=120):\n",
        "  sample = train_data.sample(frac=1).head(1)\n",
        "  context = sample.doc_tokens.values\n",
        "  print('='*separator_length)\n",
        "  print('CONTEXT: ')\n",
        "  print('='*separator_length)\n",
        "  lines = [' '.join(context[0][idx:idx+line_length]) for idx in range(0, len(context[0]), line_length)]\n",
        "  for l in lines:\n",
        "      print(l)\n",
        "  print('='*separator_length)\n",
        "  questions = train_data[train_data.doc_tokens.values==context]\n",
        "  print('QUESTION:', ' '*(3*separator_length//4), 'ANSWER:')\n",
        "  for idx, row in questions.iterrows():\n",
        "    question = row.question_text\n",
        "    answer = row.orig_answer_text\n",
        "    print(question, ' '*(2*separator_length//4-len(question)+9), (answer if answer else 'No answer found'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFuruz_Vl9xU",
        "scrolled": false,
        "outputId": "e4b2fa4f-a330-4ad4-9d12-ef8e8d7e6f85"
      },
      "source": [
        "print_squad_sample(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "CONTEXT: \n",
            "========================================================================================================================\n",
            "Breadth-first search (BFS) starts by visiting an arbitrary vertex, then visitsall vertices whose distance\n",
            "from the starting vertex is one, then all verticeswhose distance from the starting vertex\n",
            "is two, and so on. If your graph is anundirected tree, BFS performs a\n",
            "level-order tree traversal.\n",
            "========================================================================================================================\n",
            "QUESTION:                                                                                            ANSWER:\n",
            "describe BFS briefly                                                   Breadth-first search (BFS) starts by visiting an arbitrary vertex, then visitsall vertices whose distance from the starting vertex is one, then all verticeswhose distance from the starting vertex is two, and so on.\n",
            "what kind of traversal does BFS perform for an undirected tree?        If your graph is anundirected tree, BFS performs a level-order tree traversal.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "collapsed": true,
        "id": "IqvN0zNDl9xU",
        "outputId": "6588af0b-7d59-454d-ed71-3aafdeade774"
      },
      "source": [
        "# adding cols for paragraph_len and question_len in the train data\n",
        "train_data['paragraph_len'] = train_data['doc_tokens'].apply(len)\n",
        "train_data['question_len'] = train_data['question_text'].apply(len)\n",
        "# viewing first 5 entries\n",
        "train_data.sample(frac=1).head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qas_id</th>\n",
              "      <th>question_text</th>\n",
              "      <th>doc_tokens</th>\n",
              "      <th>orig_answer_text</th>\n",
              "      <th>start_position</th>\n",
              "      <th>end_position</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>paragraph_len</th>\n",
              "      <th>question_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>b95e33ac-971b-4c0c-a805-2814a98c11a1</td>\n",
              "      <td>how can we find the shortest path in an unweig...</td>\n",
              "      <td>[The, Shortest-Path, Problem•, It’s, often, us...</td>\n",
              "      <td>For an unweighted graph, we can simply do the ...</td>\n",
              "      <td>32</td>\n",
              "      <td>75</td>\n",
              "      <td>False</td>\n",
              "      <td>124</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>9d018b5c-cb9b-4841-886a-24fe5c0c922d</td>\n",
              "      <td>what does Kruskal's algorithm do?</td>\n",
              "      <td>[Kruskal’s, algorithm, computes, the, mimimum,...</td>\n",
              "      <td>Kruskal’s algorithm computes the mimimum spann...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>73</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>e046f5ea-80ae-4dc5-830c-992cecdebbc4</td>\n",
              "      <td>what is a binary tree?</td>\n",
              "      <td>[Binary, Trees, , A, binary, tree, is, either...</td>\n",
              "      <td>A binary tree is a nonlinear data structure</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>False</td>\n",
              "      <td>71</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>644e2d95-0742-4eae-9cab-bddbe4fc619d</td>\n",
              "      <td>what does the prev pointer of the first node r...</td>\n",
              "      <td>[Doubly-Linked, Lists, , Each, data, entry, i...</td>\n",
              "      <td>the first node in the list contains a prev ref...</td>\n",
              "      <td>84</td>\n",
              "      <td>95</td>\n",
              "      <td>False</td>\n",
              "      <td>109</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>41604581-b75f-44ef-a9b0-cf38e2a1c249</td>\n",
              "      <td>when is a graph strongly connected?</td>\n",
              "      <td>[A, graph, is, _strongly_connected_, if, there...</td>\n",
              "      <td>A graph is _strongly_connected_ if there is a ...</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>False</td>\n",
              "      <td>28</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   qas_id  ... question_len\n",
              "471  b95e33ac-971b-4c0c-a805-2814a98c11a1  ...           57\n",
              "375  9d018b5c-cb9b-4841-886a-24fe5c0c922d  ...           33\n",
              "117  e046f5ea-80ae-4dc5-830c-992cecdebbc4  ...           22\n",
              "80   644e2d95-0742-4eae-9cab-bddbe4fc619d  ...           54\n",
              "400  41604581-b75f-44ef-a9b0-cf38e2a1c249  ...           35\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "SmfYY15sl9xV",
        "outputId": "4b7d3292-a9e4-4d66-97e8-b909c4511cb5"
      },
      "source": [
        "# looking at the distribution of token lengths\n",
        "plt.hist(train_data['paragraph_len'])\n",
        "\n",
        "plt.hist(train_data['question_len'])\n",
        "\n",
        "# we find that most of the data lies below 150 so we set the context len to 150\n",
        "# ignore very long outliers like 450\n",
        "\n",
        "# question lengths lie below 100 so we set max to 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([101., 210., 108., 107.,  50.,  35.,  13.,   2.,   1.,   2.]),\n",
              " array([ 15. ,  24.6,  34.2,  43.8,  53.4,  63. ,  72.6,  82.2,  91.8,\n",
              "        101.4, 111. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4O_rcfzl9xV",
        "scrolled": false,
        "outputId": "8e413da7-4e98-471d-fb03-29c01ce6a8a5"
      },
      "source": [
        "max_seq_length = 256\n",
        "print(\"Percentage of context's less than max_seq_length = %s%%\" % (len([l for l in train_data['paragraph_len'] if l <= max_seq_length])/len(train_data) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of context's less than max_seq_length = 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_vVc4S-l9xW"
      },
      "source": [
        "# download a pretrained tokenizer\n",
        "# bert uncased doesn't take into account the case of the letters\n",
        "# base tokenizer is the complete one - not light version\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPMY7Bpnl9xX"
      },
      "source": [
        "# if the document is longer than the max_seq_length, we use a sliding window of size doc_stride to traverse\n",
        "doc_stride = 128\n",
        "max_seq_length = 256\n",
        "max_query_length = 64\n",
        "# batch size of 64 if RAM available.\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey4olYZgl9xX"
      },
      "source": [
        "# loads a data file into a list of input batches\n",
        "features = convert_examples_to_features(examples=examples,\n",
        "                                        tokenizer=tokenizer,\n",
        "                                        max_seq_length=max_seq_length,\n",
        "                                        doc_stride=doc_stride,\n",
        "                                        max_query_length=max_query_length,\n",
        "                                        is_training=True)\n",
        "# save to the features file\n",
        "torch.save(features, 'cached_features_file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw3V__-knnfs"
      },
      "source": [
        "# we want experiment to be reproducible\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4C2lSMXnrWJ"
      },
      "source": [
        "# Convert to Tensors and build dataset\n",
        "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n",
        "all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n",
        "\n",
        "all_start_positions = torch.tensor([f.start_position for f in features], dtype=torch.long)\n",
        "all_end_positions = torch.tensor([f.end_position for f in features], dtype=torch.long)\n",
        "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
        "                        all_start_positions, all_end_positions,\n",
        "                        all_cls_index, all_p_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAs6dqGgnvjZ"
      },
      "source": [
        "train_sampler = RandomSampler(dataset)\n",
        "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS829v85nwi5"
      },
      "source": [
        "import glob\n",
        "checkpoints = sorted(glob.glob('/drive/My Drive/Colab Notebooks/data/checkpoint*-[0-9]*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Ww6fqRqgj-"
      },
      "source": [
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxbMUdsiqhY9",
        "outputId": "aecefdce-25ce-401f-c3dc-384307415bfa"
      },
      "source": [
        "if len(checkpoints) > 0:\n",
        "  global_step = checkpoints[-1].split('-')[-1]\n",
        "  ckpt_name = '/drive/My Drive/Colab Notebooks/data/checkpoint-{}'.format(global_step)\n",
        "  print(\"Loading model from checkpoint %s\" % ckpt_name)\n",
        "  model = BertForQuestionAnswering.from_pretrained(ckpt_name)\n",
        "  train_loss_set_ckpt = torch.load(ckpt_name + '/training_loss.pt')\n",
        "  train_loss_set = to_list(train_loss_set_ckpt)\n",
        "  tr_loss = train_loss_set[-1]\n",
        "else:\n",
        "  global_step = 0\n",
        "  train_loss_set = []\n",
        "  tr_loss = 0.0\n",
        "  model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-gVDkKLq6zh",
        "outputId": "5faec178-410f-49eb-f918-84dda6001339"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "print(param_optimizer[-2])\n",
        "print(param_optimizer[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('qa_outputs.weight', Parameter containing:\n",
            "tensor([[ 0.0187,  0.0181,  0.0130,  ..., -0.0040,  0.0066,  0.0127],\n",
            "        [ 0.0109,  0.0022, -0.0203,  ...,  0.0200, -0.0169, -0.0044]],\n",
            "       device='cuda:0', requires_grad=True))\n",
            "('qa_outputs.bias', Parameter containing:\n",
            "tensor([0., 0.], device='cuda:0', requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YTtxVSfq-aD"
      },
      "source": [
        "learning_rate = 5e-5\n",
        "adam_epsilon=1e-8\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeZ2OkXOrFxA"
      },
      "source": [
        "num_train_epochs = 20\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\" % len(dataset))\n",
        "print(\"  Num Epochs = %d\" % num_train_epochs)\n",
        "print(\"  Batch size = %d\" % batch_size)\n",
        "print(\"  Total optimization steps = %d\" % (len(train_dataloader) // num_train_epochs))\n",
        "\n",
        "model.zero_grad()\n",
        "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
        "set_seed()\n",
        "\n",
        "for _ in train_iterator:\n",
        "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
        "    for step, batch in enumerate(epoch_iterator):\n",
        "      if step < global_step + 1:\n",
        "        continue\n",
        "\n",
        "      model.train()\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      inputs = {'input_ids':       batch[0],\n",
        "                'attention_mask':  batch[1], \n",
        "                'token_type_ids':  batch[2],  \n",
        "                'start_positions': batch[3], \n",
        "                'end_positions':   batch[4]}\n",
        "\n",
        "      outputs = model(**inputs)\n",
        "\n",
        "      loss = outputs[0]\n",
        "      train_loss_set.append(loss)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      tr_loss += loss.item()\n",
        "      optimizer.step()\n",
        "      model.zero_grad()\n",
        "      global_step += 1\n",
        "    \n",
        "      if global_step % 10 == 0:\n",
        "        print(\"Train loss: {}\".format(tr_loss/global_step))\n",
        "        output_dir = '/drive/My Drive/Colab Notebooks/data/checkpoint-{}'.format(global_step)\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "        torch.save(torch.tensor(train_loss_set), os.path.join(output_dir, 'training_loss.pt'))\n",
        "        print(\"Saving model checkpoint to %s\" % output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm2KiIFsrO61"
      },
      "source": [
        "output_dir = '/drive/My Drive/Colab Notebooks/data/checkpoint-final'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7zwCvxfrXEB"
      },
      "source": [
        "train_loss_set_ckpt = torch.load('/drive/My Drive/Colab Notebooks/data/checkpoint-40/training_loss.pt')\n",
        "train_loss_set = to_list(train_loss_set_ckpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kLsqIT_e892"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCDIsr3GAY-6"
      },
      "source": [
        "## Converting app to .joblib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWyERVV9ayYV"
      },
      "source": [
        "!pip install cdqa\n",
        "# #!git clone https://github.com/cdqa-suite/cdQA.git\n",
        "# %cd cdQA/\n",
        "# !pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QIFkAqYRq4J"
      },
      "source": [
        "!pip install scikit-learn==0.22\n",
        "!pip install joblib==0.14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZVQrxioP2gw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58528b9-affc-48c9-ea28-0795f133b6bd"
      },
      "source": [
        "# This is for converting the model to a .joblib so we can use streamlit to make\n",
        "# it into a web app (https://github.com/cdqa-suite/cdQA/issues/324)\n",
        "\n",
        "# Let's call your pytorch model Bert for QA custom_qa_model\n",
        "from cdqa.reader import BertQA\n",
        "\n",
        "reader = BertQA()\n",
        "reader.model = model\n",
        "\n",
        "# You need to send the model to CPU in order to save in the joblib format\n",
        "reader.model.to('cpu')\n",
        "reader.device = torch.device('cpu')\n",
        "\n",
        "# Save it in the joblib format\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "joblib.dump(reader, os.path.join(\"/drive/My Drive/Colab Notebooks/data/\", 'extended_CS231_bert.joblib'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/drive/My Drive/Colab Notebooks/data/extended_CS231_bert.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHsydH6Gu7ft"
      },
      "source": [
        "## App Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiTJADj4Q7W0"
      },
      "source": [
        "# using streamlit to create the app\n",
        "!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSeq2twXwLvm"
      },
      "source": [
        "# creates a secure tunnel through which the \n",
        "!pip install pyngrok==4.1.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkOHjYc2Q-oS"
      },
      "source": [
        "%%writefile bertdeploy.py\n",
        "import joblib\n",
        "import requests\n",
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "\n",
        "  st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "  st.title(\"Question Answering Webapp\")\n",
        "  st.text(\"What would you like to know about Data Structures today?\")\n",
        "\n",
        "  @st.cache(allow_output_mutation=True)\n",
        "\n",
        "  def load_model():\n",
        "    model = joblib.load('/content/drive/My Drive/Colab Notebooks/data/custom_qa_bert.joblib')\n",
        "    return model\n",
        "\n",
        "  with st.spinner(\"Loading model into memory ...\"):\n",
        "    model = load_model()\n",
        "\n",
        "  text = st.text_input(\"Enter your questions here...\")\n",
        "\n",
        "  if text:\n",
        "    st.write(\"Response: \")\n",
        "\n",
        "    with st.spinner(\"Searching for answers ...\"):\n",
        "      prediction = model.predict(text)\n",
        "      st.write(\"answer: {}\".format(prediction[0]))\n",
        "      st.write(\"title: {}\".format(prediction[1]))\n",
        "      st.write(\"paragraph: {}\".format(prediction[2]))\n",
        "    st.write(\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0N7rhE0xCYx"
      },
      "source": [
        "!ngrok authtoken 1nnk5fe5IOm0N1ZbjgKZktXQlgZ_3WBfRozA6g8VadzTz9vwU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ja1dCFmxNDk"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFrqBuIpxj-g"
      },
      "source": [
        "# !nohub streamlit run bertdeploy.py\n",
        "!streamlit run bertdeploy.py&>/dev/null&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCWLluW-x8k8"
      },
      "source": [
        "!pgrep streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHP0pg1DxdsG"
      },
      "source": [
        "publ_url = ngrok.connect(port='8501')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3e3sW9ayKsE"
      },
      "source": [
        "publ_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBOfqwRv4yUl"
      },
      "source": [
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}